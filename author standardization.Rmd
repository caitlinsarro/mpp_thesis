---
title: "Web Scraping"
subtitle: "Author Standardization"
author: "Caitlin Sarro"
date: "2/9/2022"
output: 
  html_document:
    toc: TRUE
    df_print: paged
    number_sections: FALSE
    highlight: tango
    theme: lumen
    toc_depth: 3
    toc_float: true
    css: custom.css 
    self_contained: false
    includes:
      after_body: footer.html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```
***


**Step 1.** Load the packages `rvest` and `stringr`.

```{r, message=F}
#install.packages("")
library(RSelenium)
library(tidyverse)
library(rvest)
library(stringr)
library(readr)

library(reshape2)
library(dplyr)

library(xml2)
library(purrr)
library(tibble)

library(data.table)

library(tm)

library(RCurl)

library(quanteda)

```



```{r}
#Capacity Building https://www.unsdglearn.org/courses/?_sf_s=capacity%20building
#Breaking the Silos https://www.unsdglearn.org/courses/?_sfm_sdg=5



coursera <- read_csv("exports/coursera_c.csv")
unsdglearn_silos <- read_csv("exports/unsdglearn_silos.csv")
unsdglearn <- read_csv("exports/unsdglearn.csv")
sdgacademy <- read_csv("exports/sdgacademy.csv")
unpan <- read_csv("exports/unpan.csv")
unssc <- read_csv("exports/unssc.csv")
unfccc <- read_csv("exports/unfccc.csv")

authors_cour <- coursera %>% select(titles, author)
authors_unsdglearn_silos <- unsdglearn_silos %>% select(titles, authors) #fix this s
authors_unsdglearn <- unsdglearn %>% select(titles, authors) #fix this s
authors_sdgacademy <- sdgacademy %>% select(titles_acad, author) #fix this standardize
authors_unpan <- unpan %>% select(titles_unpan, authors_unpan)
authors_unssc <- unssc %>% select(titles_unssc, authors)
authors_unfccc <- unfccc %>% select(titles_unfccc, author)

#fix nonstandard names to titles and authors
authors_sdgacademy <- authors_sdgacademy %>%
  rename(titles = titles_acad)

authors_unpan <- authors_unpan %>%
  rename(titles = titles_unpan)

authors_unssc <- authors_unssc %>%
  rename(titles = titles_unssc)

authors_unfccc <- authors_unfccc %>%
  rename(titles = titles_unfccc)

## authors

authors_sdgacademy <- authors_sdgacademy %>%
  rename(authors = author)

authors_cour <- authors_cour %>%
  rename(authors = author)

authors_unpan <- authors_unpan %>%
  rename(authors = authors_unpan)

authors_unfccc <- authors_unfccc %>%
  rename(authors = authors)

#combine into one set
combined <- rbind(authors_cour, authors_unsdglearn_silos, authors_unsdglearn, authors_sdgacademy, authors_unpan)

```





```{r}
#to long data
combined <- combined %>% 
  mutate(authors = strsplit(as.character(authors), ",")) %>%
  unnest(authors)

#trim leading and ending whitespaces
combined$authors <- trimws(combined$authors)

authors_list <- combined


#make a dataframe
#duplicate column
authors_list$au_category <- authors_list$authors

```


```{r}
#this category to transform
authors_list$au_category

#making the website link for a google search
#replace whitespace with + 
authors_list$piece <- gsub(" ", "_", authors_list$authors)

authors_list$weblink <- paste0("https://wikipedia.org/wiki/", authors_list$piece)
#authors_list$weblink <- paste0("https://www.google.com/search?q=", authors_list$piece)

weblink_au <- authors_list$weblink

unique(weblink_au)
url.exists("weblink_au")


authors_list

```
```{r}
#
#start RSelenium

system('docker kill $(docker ps -q)')
Sys.sleep(2)
system('docker run -d -p 4445:4444 selenium/standalone-chrome-debug:latest')
Sys.sleep(2)
system('docker container ls')

#rstudioapi::terminalExecute('java -Dwebdriver.chrome.driver="C:/Users/caitl/Documents/R #Files/selenium/chromedriver.exe" -jar "C:/Users/caitl/Documents/R #Files/selenium/selenium-server-standalone-3.141.59.jar" -port 4567')
#standalone-chrome-debug:latest


remDr <- remoteDriver(
        remoteServerAdd = "localhost",
        port = 4445L,
        browser = "chrome" 
)

remDr$open()



```


```{r}


# Run a test
weblink_test <-"https://en.wikipedia.org/wiki/Lund_University"

test <- read_html(weblink_test) %>% 
    html_nodes(xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "infobox-data", " " ))] | //*[contains(concat( " ", @class, " " ), concat( " ", "infobox-label", " " ))]') %>% 
    html_text()

test


read_html(weblink_test) %>% 
    html_nodes(xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "infobox-data", " " ))] | //*[contains(concat( " ", @class, " " ), concat( " ", "infobox-label", " " ))]') %>% 
    html_text() %>% 
    enframe("id", "category")  %>%
    mutate(weblink_test = weblink_test) 


```




```{r}
# Finding and fixing NOT-REAL-LINKS
url.exists("weblink_au")

scraper <- function(weblink_au) { tryCatch(
  read_html(weblink_au) %>% 
    html_nodes(xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "infobox-data", " " ))] | //*[contains(concat( " ", @class, " " ), concat( " ", "infobox-label", " " ))]') %>% 
    html_text() %>% 
    enframe("id", "category"),
    error = function(err) return(NULL))
}

```


```{r}

url_exists <- function(x, non_2xx_return_value = FALSE, quiet = FALSE,...) {

  suppressPackageStartupMessages({
    require("httr", quietly = FALSE, warn.conflicts = FALSE)
  })

  # you don't need thse two functions if you're alread using `purrr`
  # but `purrr` is a heavyweight compiled pacakge that introduces
  # many other "tidyverse" dependencies and this doesnt.

  capture_error <- function(code, otherwise = NULL, quiet = TRUE) {
    tryCatch(
      list(result = code, error = NULL),
      error = function(e) {
        if (!quiet)
          message("Error: ", e$message)

        list(result = otherwise, error = e)
      },
      interrupt = function(e) {
        stop("Terminated by user", call. = FALSE)
      }
    )
  }

  safely <- function(.f, otherwise = NULL, quiet = TRUE) {
    function(...) capture_error(.f(...), otherwise, quiet)
  }

  sHEAD <- safely(httr::HEAD)
  sGET <- safely(httr::GET)

  # Try HEAD first since it's lightweight
  res <- sHEAD(x, ...)

  if (is.null(res$result) || 
      ((httr::status_code(res$result) %/% 200) != 1)) {

    res <- sGET(x, ...)

    if (is.null(res$result)) return(NA) # or whatever you want to return on "hard" errors

    if (((httr::status_code(res$result) %/% 200) != 1)) {
      if (!quiet) warning(sprintf("Requests for [%s] responded but without an HTTP status code in the 200-299 range", x))
      return(non_2xx_return_value)
    }

    return(TRUE)

  } else {
    return(TRUE)
  }

}

results_urls <- data.frame(
  exists = sapply(weblink_au, url_exists, USE.NAMES = FALSE),
  weblink_au,
  stringsAsFactors = FALSE
) 

#%>% dplyr::tbl_df() %>% print()

results_urls

results_urls_fix <- results_urls[results_urls$exists == 'FALSE',]
results_urls_t <- results_urls[results_urls$exists == 'TRUE',]


#export so don't have to do again
write.csv(results_urls_t,"C:/Users/caitl/Documents/GitHub/mpp_thesis/exports/results_urls_t.csv", row.names = TRUE)


```

```{r}
#assign author categories for remaining 85
results_urls_fix
#export so don't have to do again
write.csv(results_urls_fix,"C:/Users/caitl/Documents/GitHub/mpp_thesis/exports/results_urls_fix.csv", row.names = TRUE)


```



```{r}
#THIS IS THE RIGHT ONE - already exported, try to load it first
weblink_au_t <- results_urls_t$weblink_au


# Define the AUTHORS CATEGORY worker function
scraper <- function(weblink_au_t) {read_html(weblink_au_t) %>% 
    html_nodes(xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "infobox-data", " " ))] | //*[contains(concat( " ", @class, " " ), concat( " ", "infobox-label", " " ))]') %>% 
    html_text() %>% 
    enframe("id", "category")  %>%
    mutate(weblink_au_t = weblink_au_t) 
}


# Iterate over the urls, applying the function each time
au_category_t2 <- map_dfr(weblink_au_t, scraper, .id ="id") 

au_category_t2



#export so don't have to do again
write.csv(au_category_t2,"C:/Users/caitl/Documents/GitHub/mpp_thesis/exports/au_category_t2.csv", row.names = TRUE)



```




```{r}
#group and summarize
au_category_clean <- au_category_t2 %>%
 group_by(weblink_au_t) %>%
 summarize(category = str_c(category, collapse = ", "))
au_category_clean 

#reorder by index
#au_category_clean[order(as.numeric(rownames(au_category_clean$index))),]

#au_category_clean  <- read.table(text=readClipboard(), header=TRUE)    
#au_category_clean$index <- as.numeric(row.names(au_category_clean ))
#au_category_clean [order(au_category_clean$id), ]

#separate type text from category
#au_category_clean <- str_split_fixed(au_category_clean$category, "Type,", 2)

au_category_clean <- separate(data = au_category_clean, col = category, into = c("category", "text"), sep = "Type,")

au_category_clean <- separate(data = au_category_clean, col = text, into = c("text", "remainder"), sep = ",")

au_category_clean

#remove redundant cols
au_category_clean <- mutate(au_category_clean, category=NULL, remainder=NULL)

au_category_clean$category <- au_category_clean$text

au_category_clean <- mutate(au_category_clean, text=NULL)

urls_with_cate <- au_category_clean

#reorder
#au_category_clean$id <- as.numeric(au_category_clean$id)

#au_category_clean[order(au_category_clean$id, decreasing = FALSE),] 


#merge using the index

#colnames(results_urls_t)[1] <- "id"

#as.character(results_urls_t2$id)

#urls_with_cate <-merge(results_urls_t, au_category_clean, by.x = results_urls_t$index, by.y = "id", all.y = TRUE)

#left_join(results_urls_t,au_category_clean, by = "id")

#remove redundant id
#urls_with_cate <- mutate(urls_with_cate, exists=NULL)

```


```{r}

#merge with titles
authors_list_A <- merge(authors_list, urls_with_cate, by.x = "weblink", by.y = "weblink_au_t", all.y = TRUE)
#authors_list_A
#authors_list_A <- unique(authors_list_A)

#authors_list_A 

#remove redundant cols
#authors_list_A <- mutate(authors_list_A, weblink=NULL, piece=NULL, au_category=NULL, id=NULL)
#authors_list_A

#authors_list_A <- unique(authors_list_A)
authors_list_A


```


```{r}
#combine with nonquick links
results_urls_fix_complete <- read_csv("exports/results_urls_fix_complete.csv")
results_urls_fix_complete
#merge with titles
authors_list_B <- merge(authors_list, results_urls_fix_complete, by.x = "weblink", by.y = "weblink_au", all.y = TRUE)
authors_list_A
#authors_list_A <- unique(authors_list_A)

#authors_list_A 

#remove redundant cols
#authors_list_A <- mutate(authors_list_A, weblink=NULL, piece=NULL, au_category=NULL, id=NULL)
#authors_list_A

#authors_list_A <- unique(authors_list_A)
authors_list_B

#combine lists A and B
authors_list_X <- rbind(authors_list_A, authors_list_B)
#move back into the A list name
authors_list_A <- authors_list_X
authors_list_A
```



```{r}
#Universal fixes
#trim leading and ending whitespaces
authors_list_A$category <- trimws(authors_list_A$category)
#lowercase
authors_list_A$category <- tolower(authors_list_A$category)
#remove punctuation
authors_list_A$category <- removePunctuation(authors_list_A$category)

```


```{r}
#author dictionaries
#------------------------

#df <- data.frame(text =  c('flight cancelled','dog cat','coach travel','car bus','cow sheep',' #high bar'), 
#                 transport = 0)
#words <- 'flight|flights|plane|seats|seat|travel|time|coach'


#df[grep(words, df$text, value = F), "transport"] <- 1
#taxglob = "tax*",
#taxregex = "tax.+$",

#AUTHOR dictionary
dict_au <- dictionary(list(un_programs = c("UN-Habitat", "UNDP", "UNEP", "UN Global Compact"),
                        un_specialized_agencies = c("FAO", "Food and Agriculture Organization of the United Nations", "ICAO", "International Civil Aviation Organization", "IFAD", "International Fund for Agricultural Development","International Labour Organization","IMF","International Monetary Fund","IMO","International Maritime Organization","ITU","International Telecommunication Union","UNESCO","United Nations Educational Scientific and Cultural Organization","UNIDO","United Nations Industrial Development Organization","UNWTO","World Tourism Organization","UPU","Universal Postal Union","WHO","World Health Organization","WIPO","World Intellectual Property Organization","WMO","World Meteorological Organization","World Bank Group","World Bank"),
                        un = c("UN DESA", "UN Statistics Division", "United Nations Statistics Division", "United Nations Global Compact Academy", "United Nations Global Compact Academy","UNDCO","UNGCA","UNITAR")))


dfmat_ex <- dfm(tokens(authors_list_A$authors, remove_punct = TRUE))
d_au <- dfm_lookup(dfmat_ex, dict_au)
df_au <- as.data.frame(as.matrix(d_au))
df_au$id <- seq.int(nrow(df_au))



#------------------------------

#CATEGORY dictionary
dict_cat <- dictionary(list(
                        ngo = c("501", "nonprofit", "non-profit", "non-governmental", "nongovernmental","Non-governmental organization","Non-governmental","NGO","ingo","ngo","nongovernmental","philanthropic initiative","Foundation","501c3")))





dfmat_ex <- dfm(tokens(authors_list_A$category, remove_punct = TRUE))
d_cat <- dfm_lookup(dfmat_ex, dict_cat)
df_cat <- as.data.frame(as.matrix(d_cat))
df_cat$id <- seq.int(nrow(df_cat))


#------------------------------------


```





```{r}
#transform into a leaner dataframe
#authors_list_A_comb <- mutate(authors_list_A, titles=NULL, piece=NULL, weblink=NULL, au_category=NULL)

#adding index as a col for matching
authors_list_A$id <- seq.int(nrow(authors_list_A))

#start to combine
 
authors_list_A_comb <- left_join(authors_list_A,df_au, by = "id") 
authors_list_A_comb <- left_join(authors_list_A_comb,df_cat, by = "id") 


#authors_list_A_comb <- left_join(authors_list_A,df, by = "authors") 
#authors_list_A_comb <- merge(authors_list_A,df, by = "authors")
#authors_list_A_comb <- left_join(authors_list_A_comb,df_agent, by = "authors")
#authors_list_A_comb <- left_join(authors_list_A_comb,df_ngo, by = "category")
#authors_list_A_comb <- left_join(authors_list_A_comb,df_un, by = "authors")
#authors_list_A_comb

authors_list_A_comb$category[authors_list_A_comb$un_programs=="1"] <- "un program"
authors_list_A_comb$category[authors_list_A_comb$un_specialized_agencies=="1"] <- "un specialized agency"
authors_list_A_comb$category[authors_list_A_comb$ngo=="1"] <- "ngo"
authors_list_A_comb$category[authors_list_A_comb$un=="1"] <- "un"


authors_list_A_comb
```

```{r}
#cut unnessesary columns before fixing

#authors_list_A_comb <- mutate(authors_list_A_comb, un_programs=NULL, un_specialized_agencies=NULL, ngo=NULL, un=NULL)

#authors_list_A_comb <- unique(authors_list_A_comb)
#authors_list_A_comb

```





```{r}
#manual fixing based on authors
authors_list_A_comb$category[authors_list_A_comb$authors=="Academy of Korean Studies"] <- "research institute" 

authors_list_A_comb$category[authors_list_A_comb$authors=="African Center for Cities"] <- "research institute" 


authors_list_A_comb$category[authors_list_A_comb$authors=="African Center for Cities"] <- "research institute" 

authors_list_A_comb$category[authors_list_A_comb$authors=="African Local Government Academy"] <- "government network" 

authors_list_A_comb$category[authors_list_A_comb$authors=="Ain Shams University"] <- "public university" 

authors_list_A_comb$category[authors_list_A_comb$authors=="Alliance for Global Water Adaptation"] <- "ngo" 

authors_list_A_comb$category[authors_list_A_comb$authors=="American Museum of Natural History"] <- "cultural institution" 

authors_list_A_comb$category[authors_list_A_comb$authors=="Athens University of Economics and Business"] <- "public university" 


authors_list_A_comb$category[authors_list_A_comb$authors=="Columbia University"] <- "private research university" 


authors_list_A_comb$category[authors_list_A_comb$authors=="Cornell University"] <- "private research university" 


authors_list_A_comb$category[authors_list_A_comb$authors=="Belize National Institute of Culture and History"] <- "cultural institution" 

authors_list_A_comb$category[authors_list_A_comb$authors=="Banco Interamericano de Desarrollo"] <- "finance" 

authors_list_A_comb$category[authors_list_A_comb$authors=="Federal Government"] <- "government" 

authors_list_A_comb$category[authors_list_A_comb$authors=="UNSSC"] <- "un internal agency" 

authors_list_A_comb$category[authors_list_A_comb$authors=="Global Environment Facility"] <- "government network" 

authors_list_A_comb$category[authors_list_A_comb$authors=="Seoul National University"] <- "public research university" 

authors_list_A_comb$category[authors_list_A_comb$authors=="Sustainable Development Solutions Network|SDSN"] <- "un ngo" 

authors_list_A_comb$category[authors_list_A_comb$authors=="SDG Academy"] <- "un ngo" 

authors_list_A_comb$category[authors_list_A_comb$authors=="Cities Alliance"] <- "intergovernmental organization" 

authors_list_A_comb$category[authors_list_A_comb$authors=="OECD_PCSD"] <- "intergovernmental organization" 

authors_list_A_comb$category[authors_list_A_comb$authors=="Public Health Foundation of India"] <- "ngo" 

authors_list_A_comb$category[authors_list_A_comb$authors=="Brookings"] <- "research institute" 

authors_list_A_comb$category[authors_list_A_comb$authors=="Supranational"] <- "government" 

authors_list_A_comb$category[authors_list_A_comb$authors=="Chatham House"] <- "public policy think tank" 

authors_list_A_comb$category[authors_list_A_comb$authors=="Howard Hughes Medical Institute"] <- "ngo" 

authors_list_A_comb$category[authors_list_A_comb$authors=="Natural Resource Governance Institute"] <- "ngo" 

authors_list_A_comb$category[authors_list_A_comb$authors=="Roman Catholic Church"] <- "cultural institution" 

authors_list_A_comb$category[authors_list_A_comb$authors=="University of Colorado System"] <- "public university" 

authors_list_A_comb$category[authors_list_A_comb$authors=="University of Manchester"] <- "public research university" 

authors_list_A_comb$category[authors_list_A_comb$authors=="UNOG"] <- "un" 

authors_list_A_comb$category[authors_list_A_comb$authors=="World Business Council for Sustainable Development"] <- "business"


```

```{r}
#------------- category cleanups
authors_list_A_comb$category[authors_list_A_comb$category=="public"] <- "public university"

authors_list_A_comb$category[authors_list_A_comb$category=="private"] <- "private university"

authors_list_A_comb$category[authors_list_A_comb$category=="501c3"] <- "ngo"

authors_list_A_comb$category[authors_list_A_comb$category=="501c3 nonprofit organization1"] <- "ngo"

authors_list_A_comb$category[authors_list_A_comb$category=="private  not for profit"] <- "ngo"


authors_list_A_comb$category[authors_list_A_comb$category=="nongovernmental organization ngo"] <- "ngo"

authors_list_A_comb$category[authors_list_A_comb$category=="united nations specialised agency"] <- "un specialized agency"

authors_list_A_comb$category[authors_list_A_comb$category=="united nations specialized agency"] <- "un specialized agency"

authors_list_A_comb$category[authors_list_A_comb$category=="intergovernmental organisation"] <- "intergovernmental organization"

authors_list_A_comb$category[authors_list_A_comb$category=="intergovernmental organisation"] <- "intergovernmental organization"

authors_list_A_comb$category[authors_list_A_comb$category=="Federal Government"] <- "government"

authors_list_A_comb$category[authors_list_A_comb$category=="research institution"] <- "research institute"

authors_list_A_comb$category[authors_list_A_comb$category=="research and training institute"] <- "research institute"

authors_list_A_comb$category[authors_list_A_comb$category=="programme"] <- "un program"

authors_list_A_comb$category[authors_list_A_comb$category=="public research university"] <- "public research university"

authors_list_A_comb$category[authors_list_A_comb$category=="public university system"] <- "public university"

authors_list_A_comb$category[authors_list_A_comb$category=="public research university
ancient university"] <- "public research university"

authors_list_A_comb$category[authors_list_A_comb$category=="public research university1"] <- "public research university"

authors_list_A_comb$category[authors_list_A_comb$category=="public research university
ancient university"] <- "public research university"

authors_list_A_comb$category[authors_list_A_comb$category=="public landgrant research university"] <- "public research university"

authors_list_A_comb$category[authors_list_A_comb$category=="private landgrant research university"] <- "private research university"

authors_list_A_comb$category[authors_list_A_comb$category=="public staterelated landgrant flagship research university"] <- "public research university"

authors_list_A_comb$category[authors_list_A_comb$category=="publicdistance educationmega university"] <- "public research university"

authors_list_A_comb$category[authors_list_A_comb$category=="public medical university"] <- "public university"

authors_list_A_comb$category[authors_list_A_comb$category=="international financial institution"] <- "finance"

authors_list_A_comb$category[authors_list_A_comb$category=="public limited company"] <- "business"

authors_list_A_comb$category[authors_list_A_comb$category=="Department of Nuclear Science and Technology"] <- "research institute"

authors_list_A_comb$category[authors_list_A_comb$category=="governmentrun"] <- "government"

authors_list_A_comb$category[authors_list_A_comb$category=="catholic"] <- "cultural institution"

authors_list_A_comb$category[authors_list_A_comb$category=="primary organ  regional branch"] <- "un primary organ"

authors_list_A_comb$category[authors_list_A_comb$category=="primary organ â€“ regional branch"] <- "un primary organ"


```

```{r}
#wider export (useful for checking)
#write.csv(authors_list_A_comb,"C:/Users/caitl/Documents/GitHub/mpp_thesis/exports/authors_list_A_comb.csv", row.names = TRUE)

```


```{r}
#move to wider au_category title
authors_list_A_comb$au_category <-authors_list_A_comb$category

#subet clean
au_category_clean <- authors_list_A_comb[c("titles","authors","au_category")]

```




```{r}
#remove duplicates
au_category_clean <- unique(au_category_clean)
#export
write.csv(au_category_clean,"C:/Users/caitl/Documents/GitHub/mpp_thesis/exports/au_category_clean.csv", row.names = TRUE)

```

```{r}
#if adding in new courses post-authorship (softcode)
au_category_clean <- read_csv("exports/au_category_clean.csv")
au_category_clean


```
```{r}
#simplified categories

#government
au_category_clean$au_category[au_category_clean$au_category=="government network"] <- "government" 
au_category_clean$au_category[au_category_clean$au_category=="intergovernmental organization"] <- "government"
au_category_clean$au_category[au_category_clean$au_category=="supranational union"] <- "government"
#ngo
au_category_clean$au_category[au_category_clean$au_category=="philanthropic initiative"] <- "ngo"

#research & policy institute
au_category_clean$au_category[au_category_clean$au_category=="policy institute"] <- "research  policy institutes"
au_category_clean$au_category[au_category_clean$au_category=="public policy think tank"] <- "research  policy institutes"
au_category_clean$au_category[au_category_clean$au_category=="research institute"] <- "research  policy institutes"

#private university
au_category_clean$au_category[au_category_clean$au_category=="private research university"] <- "private university"

#public university
au_category_clean$au_category[au_category_clean$au_category=="public research university"] <- "public university"
au_category_clean$au_category[au_category_clean$au_category=="public research university"] <- "public university"

#un
au_category_clean$au_category[au_category_clean$au_category=="department"] <- "un" 
au_category_clean$au_category[au_category_clean$au_category=="un primary organ"] <- "un" 
au_category_clean$au_category[au_category_clean$au_category=="un specialized agency"] <- "un" 
au_category_clean$au_category[au_category_clean$au_category=="un program"] <- "un" 
au_category_clean$au_category[au_category_clean$au_category=="un internal agency"] <- "un" 



```




```{r}
#group by author category

table(au_category_clean$au_category) 

```






```{r}
#repeat code?

au_category_clean <- au_category %>%
 group_by(id) %>%
 summarize(category = str_c(category, collapse = ", "))
au_category_clean 


#separate type text from category
#au_category_clean <- str_split_fixed(au_category_clean$category, "Type,", 2)

au_category_clean <- separate(data = au_category_clean, col = category, into = c("category", "text"), sep = "Type,")

au_category_clean <- separate(data = au_category_clean, col = text, into = c("text", "remainder"), sep = ",")

au_category_clean

#remove redundant cols
au_category_clean <- mutate(au_category_clean, category=NULL, remainder=NULL)

au_category_clean$category <- au_category_clean$text

au_category_clean <- mutate(au_category_clean, text=NULL)

au_category_clean

#reorder
au_category_clean$id <- as.numeric(au_category_clean$id)

au_category_clean[order(au_category_clean$id, decreasing = FALSE),] 


authors_list$id <- as.numeric(authors_list$id)
authors_list



```


```{r}
#probably need later?
authors_corpus <- VCorpus(VectorSource(authors))
# Extra whitespace is eliminated by:
authors_corpus <- tm_map(authors_corpus, stripWhitespace)
# Conversion to lower case by:
authors_corpus <- tm_map(authors_corpus, content_transformer(tolower))
#Removal of stopwords by:
authors_corpus <- tm_map(authors_corpus, removeWords, stopwords("english"))
#Stemming is done by:
tm_map(authors_corpus, stemDocument)

 dtm <- DocumentTermMatrix(authors_corpus)
 inspect(dtm)



```





```{r}
chart_df <- data.frame(titles, authors, tags, SDGs, weblink)

knitr::kable(chart_df  %>% head(10))

chart_df <- tibble::rowid_to_column(chart_df, "id")

```



```{r}

#unsdglearn_subpage <- read_html("https://www.unsdglearn.org/courses/unido-industrial-analytics-platform-iap/")
```


```{r}

# Define the KEYWORDS worker function
scraper <- function(weblink) {
  read_html(weblink) %>% 
    html_nodes(xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "keyword", " " ))]') %>% 
    html_text() %>% 
    enframe("id", "keywords")
}

# Iterate over the urls, applying the function each time
keywords <- map_dfr(weblink, scraper, .id = "id")

```


```{r}

# Define the AUDIENCE worker function
scraper <- function(weblink) {
  read_html(weblink) %>% 
    html_nodes(xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "resource-contentblock", " " )) and (((count(preceding-sibling::*) + 1) = 3) and parent::*)]//*[contains(concat( " ", @class, " " ), concat( " ", "wrapper", " " ))]') %>% 
    html_text() %>% 
    enframe("id", "audience")
}

# Iterate over the urls, applying the function each time
audience <- map_dfr(weblink, scraper, .id = "id")
audience


```


```{r}

#Combine into single columns

keywords_combined <- keywords %>%
 group_by(id) %>%
 summarize(keywords = str_c(keywords, collapse = ", "))

#df3 <- merge(audience, keywords_combined, by = "id")

chart_df <- merge(chart_df, keywords_combined, by = "id")
combined <- merge(chart_df, audience, by = "id", all = TRUE)

write.csv(combined,"C:/Users/caitl/Documents/GitHub/thesis/exports/unsdglearn.csv", row.names = TRUE)


```

```{r}

authors_list <- as.data.frame(authors_list)

write.csv(authors_list,"C:/Users/caitl/Documents/GitHub/mpp_thesis/exports/authors_list.csv", row.names = TRUE)

au_category_clean

au_category_list <- as.data.frame(au_category_clean)

write.csv(au_category_list,"C:/Users/caitl/Documents/GitHub/mpp_thesis/exports/au_category_list.csv", row.names = TRUE)


write.csv(results_urls,"C:/Users/caitl/Documents/GitHub/mpp_thesis/exports/results_urls.csv", row.names = TRUE)

write.csv(au_category_clean,"C:/Users/caitl/Documents/GitHub/mpp_thesis/exports/au_category_clean.csv", row.names = TRUE)


write.csv(authors_list_A,"C:/Users/caitl/Documents/GitHub/mpp_thesis/exports/authors_list_A.csv", row.names = TRUE)

```









```{r}
#long way
#------------------------UN PROGRAMS

un_programs <- c('UN-Habitat|UNDP|UNEP|UN Global Compact')

df <- data.frame(unique(authors_list_A$authors), un_programs = 0)
colnames(df)[1] <- "authors"
df[grep(un_programs, df$authors, value = F), "un_programs"] <- 1
df <- df[order(df$un_programs, decreasing = TRUE),] %>% unique()

df

#------------------------UN SPECIALIZED AGENCIES
un_specialized_agencies <-
  c('FAO|Food and Agriculture Organization of the United Nations|ICAO|International Civil Aviation Organization|IFAD|International Fund for Agricultural Development|ILO|International Labour Organization|IMF|International Monetary Fund|IMO|International Maritime Organization|ITU|International Telecommunication Union|UNESCO|United Nations Educational Scientific and Cultural Organization|UNIDO|United Nations Industrial Development Organization|UNWTO|World Tourism Organization|UPU|Universal Postal Union|WHO|World Health Organization|WIPO|World Intellectual Property Organization|WMO|World Meteorological Organization|World Bank Group|World Bank')
df_agent <- data.frame(authors_list_A$authors, un_specialized_agencies = 0)
colnames(df_agent)[1] <- "authors"
df_agent[grep(pattern = un_specialized_agencies, df_agent$authors, value = F), "un_specialized_agencies"] <- 1
df_agent <- df_agent[order(df_agent$un_specialized_agencies, decreasing = TRUE),] %>% unique()

df_agent

#------------------------UN
un <-
  c('UN DESA|UN Statistics Division|United Nations Statistics Division|United Nations Global Compact Academy|UNDCO|UNGCA|UNITAR')
df_un <- data.frame(authors_list_A$authors, un = 0)
colnames(df_un)[1] <- "authors"
df_un[grep(un, df_un$authors, value = F), "un"] <- 1
df_un <- df_un[order(df_un$un, decreasing = TRUE),] %>% unique()
df_un

#sapply(un, function(x) df_un$authors[grepl(x, df_un$authors)])

#sapply(un, function(x) df_un[grepl(x, un)])



#------------------------NONProfit
#space clear rm(unsdglearn,unsdglearn_silos,coursera)
ngo <-
  c('501','nonprofit','non-profit','non-governmental','nongovernmental','Non-governmental organization','Non-governmental','NGO','ngo','ingo','nongovernmental','philanthropic initiative')
df_ngo <- data.frame(authors_list_A$category, ngo = 0)
colnames(df_ngo)[1] <- "category"
df_ngo[grep(pattern = ngo, df_ngo$category, value = F), "ngo"] <- 1
df_ngo <- df_ngo[order(df_ngo$ngo, decreasing = TRUE),] %>% unique()
df_ngo

#sapply(ngo, function(x) df_ngo$authors[grepl(x, df_ngo$authors)])


#------------------



#------------------ If Coded, Change Category
#df
#df_agent 262
#authors_list_A
#add on new columns
#522
#authors_list_A
#df

```
```{r}
#Don't run, old code

un_specialized_agencies <-
  c(
    "FAO",
    "Food and Agriculture Organization of the United Nations",
    "ICAO",
    "International Civil Aviation Organization",
    "IFAD",
    "International Fund for Agricultural Development",
    "ILO",
    "International Labour Organization",
    "IMF",
    "International Monetary Fund",
    "IMO",
    "International Maritime Organization",
    "ITU",
    "International Telecommunication Union",
    "UNESCO",
    "United Nations Educational Scientific and Cultural Organization",
    "UNIDO",
    "United Nations Industrial Development Organization",
    "UNWTO",
    "World Tourism Organization",
    "UPU",
    "Universal Postal Union",
    "WHO",
    "World Health Organization",
   "WIPO",
    "World Intellectual Property Organization",
    "WMO",
    "World Meteorological Organization",
    "World Bank Group",
    "World Bank"
  )

un_programs <-c("UN-Habitat", "UNDP", "UNEP", "UN Global Compact")

str_detect(authors_list_A$authors, un_specialized_agencies)
authors_list_A$category[authors_list_A$authors

                        
dictionary <- data.frame(search="un_specialized_agencies")
result <- authors_list_A$authors %>%
  filter(grepl(paste(dictionary$search, collapse="|"), text)) 

authors_list_A$C <- ifelse(grepl(un_specialized_agencies, authors_list_A$authors), "yes", "no")
                        
test<-authors_list_A$authors[str_detect(authors_list_A$authors, un_specialized_agencies),]
test

df <- data.frame(text =  c('UN-Habitat', 'UNDP', 'UNEP', 'UN Global Compact'), 
                 un_programs = 0)



authors_list_A %>%
    bind_cols(un_specialized_agencies %>% 
                  set_names() %>% 
                  map_dfc(~str_detect(authors_list_A$authors, .x)) %>% 
                  mutate_all(as.numeric)) %>% 
    as_tibble()

data2 <- iris[iris$Species %like% "virg", ]

```

```{r}
# OLD CODE DON'T RUN
weblink_au_t <- results_urls_t$weblink_au


# Define the AUTHORS CATEGORY worker function
scraper <- function(weblink_au_t) {read_html(weblink_au_t) %>% 
    html_nodes(xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "infobox-data", " " ))] | //*[contains(concat( " ", @class, " " ), concat( " ", "infobox-label", " " ))]') %>% 
    html_text() %>% 
    enframe("id", "category")
}


# Iterate over the urls, applying the function each time
au_category_t <- map_dfr(weblink_au_t, scraper, .id = "id") 

au_category_t

#    html_text() %>% 
#    enframe("id", "category"),
#    error = function(err) {print(NA)}
#  )}
```


```{r}
#old code
#keywords_nodes <- html_nodes(unsdglearn_subpage, 
#                           xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", #"keyword", " " ))]')
#keywords <- html_text(keywords_nodes)
#keywords


#audience_nodes <- html_nodes(unsdglearn_subpage, 
#                           xpath = '//*[(@id = "content")]//li')
#audience <- html_text(audience_nodes)
#audience


```


```{r}
#Not currently using - old code
# Define the AUTHORS CATEGORY worker function
scraper <- function(weblink_au) { tryCatch(
  read_html(weblink_au) %>% 
    html_nodes(xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "infobox-data", " " ))] | //*[contains(concat( " ", @class, " " ), concat( " ", "infobox-label", " " ))]') %>% 
    html_text() %>% 
    enframe("id", "category"),
    error = function(err) return(NULL))
}


# Iterate over the urls, applying the function each time
au_category <- map_dfr(weblink_au, scraper, .id = "id")

au_category

#    html_text() %>% 
#    enframe("id", "category"),
#    error = function(err) {print(NA)}
#  )}
```
