---
title: "Web Scraping"
subtitle: "Author Standardization"
author: "Caitlin Sarro"
date: "2/9/2022"
output: 
  html_document:
    toc: TRUE
    df_print: paged
    number_sections: FALSE
    highlight: tango
    theme: lumen
    toc_depth: 3
    toc_float: true
    css: custom.css 
    self_contained: false
    includes:
      after_body: footer.html
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```
***


**Step 1.** Load the packages `rvest` and `stringr`.

```{r, message=F}
#install.packages("")
library(RSelenium)
library(tidyverse)
library(rvest)
library(stringr)
library(readr)

library(reshape2)
library(dplyr)

library(xml2)
library(purrr)
library(tibble)

library(data.table)

library(tm)

library(RCurl)

library(quanteda)

#for categorization
library(quanteda)
library(tidytext)
#library(quanteda.textmodels)
#library(caret)
library(SnowballC)

library(topicmodels)

```



```{r}
#Capacity Building https://www.unsdglearn.org/courses/?_sf_s=capacity%20building
#Breaking the Silos https://www.unsdglearn.org/courses/?_sfm_sdg=5



coursera <- read_csv("exports/coursera_c.csv")
unsdglearn_silos <- read_csv("exports/unsdglearn_silos.csv")
unsdglearn <- read_csv("exports/unsdglearn.csv")
sdgacademy <- read_csv("exports/sdgacademy.csv")


keywords_cour <- coursera %>% select(titles, keywords)
keywords_unsdglearn_silos <- unsdglearn_silos %>% select(titles, keywords) #fix this s
keywords_unsdglearn <- unsdglearn %>% select(titles, keywords) #fix this s
keywords_sdgacademy <- sdgacademy %>% select(titles_acad, keywords) #fix this standardize

# descrp_acad


#combine into one set
combined <- rbind(keywords_cour, keywords_unsdglearn_silos, keywords_unsdglearn, keywords_sdgacademy)

```





```{r}
#to long data
# combined <- sdgacad_df_mini

#combined <- combined %>% 
#  mutate(keywords = strsplit(as.character(keywords), ",")) %>%
#  unnest(keywords)

#trim leading and ending whitespaces
#combined$keywords <- trimws(combined$keywords)

descrp_list <- sdgacad_df_mini
#combined

#make a dataframe
#duplicate column (safety redudancy)
descrp_list$key_category <- descrp_list$description


dfmat_descrip <- dfm(tokens(descrp_list$key_category, remove_punct = TRUE))

descrp_list$key_category
```

```{r}
#test using a prefab dictionary

dict <- dictionary(file = "data/dictionary/policy_agendas_english.lcd")

#dfm(dfmat1, remove = stopwords("english"), stem = TRUE, verbose = TRUE)

dfmat_descrip <- dfm(tokens(descrp_list$key_category, remove_punct = TRUE, tolower = TRUE, stem = TRUE, verbose = TRUE))
dfm_wordstem(dfmat_descrip)
#dfmat_descrip <-dfm(dfmat_descrip, remove_punct = TRUE, tolower = TRUE, stem = TRUE, verbose = TRUE)

d_descrip <- dfm_lookup(dfmat_descrip, dict)
d_descrip <- as.data.frame(as.matrix(d_descrip))
d_descrip$id <- seq.int(nrow(d_descrip))

d_descrip


```

```{r}
#import text from  Glass, L., & Newig, J. (2019). Governance for achieving the sustainable development goals: How important are participation, policy coherence, reflexivity, adaptation and democratic institutions? Earth System Governance, 2, 100031. doi:10.1016/j.esg.2019.100031

#-------PARTICIPATION
participation <- read_csv("data/dictionary/glass newig/participation.csv")

tidy_participation<- participation %>%
    unnest_tokens("word", Terms)

#remove stopwords
data("stop_words")
    tidy_participation<-tidy_participation %>%
      anti_join(stop_words)
    
#remove punctuation
#tidy_participation<-tidy_participation[-grep("\\b\\d+\\b", tidy_participation$word),]
tidy_participation$word<- gsub("[[:punct:]]|[[:digit:]]|^http:\\/\\/.*|^https:\\/\\/.*","",tidy_participation$word)

#to lowercase
tidy_participation$word<- tolower(tidy_participation$word)

#remove whitespace
tidy_participation$word <- gsub("\\s+","",tidy_participation$word)

#stemming the keywords
tidy_participation<-tidy_participation %>%
      mutate_at("word", funs(wordStem((.), language="en")))


#see most frequent   
#tidy_participation %>%
#  count(word) %>%
#    arrange(desc(n))

#keep unique values
tidy_participation <- unique(tidy_participation)

policy_coherence <- read_csv("data/dictionary/glass newig/policy coherence.csv")
reflexivity_and_adaptation <- read_csv("data/dictionary/glass newig/reflexivity and adaptation.csv")

#terms into a character list
participation_keystems <- tidy_participation$word
participation_keystems <- as.list(tidy_participation$word)


participation_keystems <- as.list(tidy_participation)
names(participation_keystems)
participation_keystems

```








```{r}
#import text from  Glass, L., & Newig, J. (2019). Governance for achieving the sustainable development goals: How important are participation, policy coherence, reflexivity, adaptation and democratic institutions? Earth System Governance, 2, 100031. doi:10.1016/j.esg.2019.100031

#-------POLICY COHERENCE
policy_coherence <- read_csv("data/dictionary/glass newig/policy coherence.csv")

tidy_policy_c<- policy_coherence %>%
    unnest_tokens("word", Terms)

#remove stopwords
data("stop_words")
    tidy_policy_c<-tidy_policy_c %>%
      anti_join(stop_words)
    
#remove punctuation
#tidy_participation<-tidy_participation[-grep("\\b\\d+\\b", tidy_participation$word),]
tidy_policy_c$word<- gsub("[[:punct:]]|[[:digit:]]|^http:\\/\\/.*|^https:\\/\\/.*","",tidy_policy_c$word)

#to lowercase
tidy_policy_c$word<- tolower(tidy_policy_c$word)

#remove whitespace
tidy_policy_c$word <- gsub("\\s+","",tidy_policy_c$word)

#stemming the keywords
tidy_policy_c<-tidy_policy_c %>%
      mutate_at("word", funs(wordStem((.), language="en")))


#see most frequent   
#tidy_participation %>%
#  count(word) %>%
#    arrange(desc(n))

#keep unique values
tidy_policy_c <- unique(tidy_policy_c)
tidy_policy_c


#terms into a character list
policy_coh_keystems <- tidy_policy_c$word #pick one
policy_coh_keystems <- as.list(tidy_policy_c)
names(policy_coh_keystems)
policy_coh_keystems

policy_coh_keystems <- as.list(tidy_policy_c)
names(policy_coh_keystems)
policy_coh_keystems


```


```{r}
#import text from  Glass, L., & Newig, J. (2019). Governance for achieving the sustainable development goals: How important are participation, policy coherence, reflexivity, adaptation and democratic institutions? Earth System Governance, 2, 100031. doi:10.1016/j.esg.2019.100031

#-------DEMOCRATIC INSTITUTIONS
democratic_institutions <- read_csv("data/dictionary/glass newig/democratic institutions .csv")

tidy_democratic <- democratic_institutions %>%
    unnest_tokens("word", Terms)

#remove stopwords
data("stop_words")
    tidy_democratic <- tidy_democratic %>%
      anti_join(stop_words)
    
#remove punctuation
#tidy_participation<-tidy_participation[-grep("\\b\\d+\\b", tidy_participation$word),]
tidy_democratic$word <- gsub("[[:punct:]]|[[:digit:]]|^http:\\/\\/.*|^https:\\/\\/.*","", tidy_democratic$word)

#to lowercase
tidy_democratic$word<- tolower(tidy_democratic$word)

#remove whitespace
tidy_democratic$word <- gsub("\\s+","",tidy_democratic$word)

#stemming the keywords
tidy_democratic <- tidy_democratic %>%
      mutate_at("word", funs(wordStem((.), language="en")))


#see most frequent   
#tidy_participation %>%
#  count(word) %>%
#    arrange(desc(n))

#keep unique values
tidy_democratic <- unique(tidy_democratic)

policy_coherence <- read_csv("data/dictionary/glass newig/policy coherence.csv")
reflexivity_and_adaptation <- read_csv("data/dictionary/glass newig/reflexivity and adaptation.csv")




#terms into a character list
democratic_keystems <- tidy_democratic$word
democratic_keystems <- as.list(tidy_democratic$word)


democratic_keystems <- as.list(tidy_democratic)
names(democratic_keystems)
democratic_keystems
```





```{r}
#import text from  Glass, L., & Newig, J. (2019). Governance for achieving the sustainable development goals: How important are participation, policy coherence, reflexivity, adaptation and democratic institutions? Earth System Governance, 2, 100031. doi:10.1016/j.esg.2019.100031

#-------REFLEXIVITY AND ADAPTATION INSTITUTIONS
reflexivity_and_adaptation <- read_csv("data/dictionary/glass newig/reflexivity and adaptation.csv")

tidy_reflex_adapt <- reflexivity_and_adaptation %>%
    unnest_tokens("word", Terms)

#remove stopwords
data("stop_words")
    tidy_reflex_adapt <- tidy_reflex_adapt %>%
      anti_join(stop_words)
    
#remove punctuation
#tidy_participation<-tidy_participation[-grep("\\b\\d+\\b", tidy_participation$word),]
tidy_reflex_adapt$word <- gsub("[[:punct:]]|[[:digit:]]|^http:\\/\\/.*|^https:\\/\\/.*","", tidy_reflex_adapt$word)

#to lowercase
tidy_reflex_adapt$word<- tolower(tidy_reflex_adapt$word)

#remove whitespace
tidy_reflex_adapt$word <- gsub("\\s+","",tidy_reflex_adapt$word)

#stemming the keywords
tidy_reflex_adapt <- tidy_reflex_adapt %>%
      mutate_at("word", funs(wordStem((.), language="en")))


#see most frequent   
#tidy_participation %>%
#  count(word) %>%
#    arrange(desc(n))

#keep unique values
tidy_reflex_adapt <- unique(tidy_reflex_adapt)



#terms into a character list
reflex_adpt_keystems <- tidy_reflex_adapt$word
reflex_adpt_keystems <- as.list(tidy_reflex_adapt$word)


reflex_adpt_keystems <- as.list(tidy_reflex_adapt)
names(reflex_adpt_keystems)
reflex_adpt_keystems


```

```{r}

#PARTICIPATION dictionary
dict_descrip <- dictionary(list(participation_keystems = c("particip", "capabl", "econom", "propos", "assess", "relev", "polici", "measur", "implement", "associ", "compet", "busi", "societ", "develop", "social", "actor", "represent", "stakehold", "involv", "collabor", "govern", "approach", "institution", "interact", "build", "trust", "share", "understand", "increas", "commit", "consensus", "decis", "accept", "facilit", "specif", "knowledg", "valu", "resourc", "conceptu", "clarif", "note", "articl", "refer", "polit", "citizen", "elect", "aspect", "form", "concept", "democrat", "institut", "discuss", "adopt", "activ", "matter", "indirect", "government", "affair", "vote", "extend", "engag", "participation", "stakeholders", "multi-stakeholders","cooperation"),
                             policy_coh_keystems = c("polici", "coher", "extent", "institut", "structur", "foster", "coordin", "implement", "interministeri","communic", "normat", "govern", "agenda", "effect", "framework", "sustain", "develop", "adapt", "arrang", "process", "increas", "design", "aid", "systemat", "promot", "mutual", "reinforc", "action", "depart", "agenc", "creat", "synergi", "achiev", "defin", "object", "integr", "approach", "complex", "issu", "network", "theori", "common", "goal", "overcom", "silo", "mental", "sector", "level", "polit", "commit", "strong", "leadership", "contribut", "reduct", "trade", "off", "enhanc", "align", "econom", "social", "environment", "reduc", "unintend", "consequ", "inform", "decis", "diverg", "target", "stronger", "focus", "interrel", "time", "consum", "effort", "interact", "product", "feedback", "policy coherence","coherence"),
                               democratic_keystems = c("democrat", "institut", "qualiti", "includ", "elector", "process", "media", "freedom", "access", "inform", "civil", "right", "polit", "liberti", "rule", "law", "govern", "account", "transpar", "effici", "effect", "countri", "develop", "facilit", "collect", "action", "reduct", "transact", "cost", "public", "percept", "credibl", "express", "free", "elect", "fair", "inclus", "legislatur", "check", "balanc", "altern", "respect", "human", "independ", "judiciari", "theori", "legitim", "peopl", "liber", "democraci", "voter", "univers", "franchis", "pluralist", "citizen", "hold", "competit", "system", "equal", "autocraci", "regim", "represent", "peace"),
                               reflex_adpt_keystems = c("democrat", "institut", "qualiti", "includ", "elector", "process", "media", "freedom", "access", "inform", "civil", "right", "polit", "liberti", "rule", "law", "govern", "account", "transpar", "effici", "effect", "countri", "develop", "facilit", "collect", "action", "reduct", "transact", "cost", "public", "percept", "credibl", "express", "free", "elect", "fair", "inclus", "legislatur", "check", "balanc", "altern", "respect", "human", "independ", "judiciari", "theori", "legitim", "peopl", "liber", "democraci", "voter", "univers", "franchis", "pluralist", "citizen", "hold", "competit", "system", "equal", "autocraci", "regim", "represent")))



dfmat_descrip <- dfm(tokens(descrp_list$key_category, remove_punct = TRUE))
d_descrip_ref <- dfm_lookup(dfmat_descrip, dict_descrip)
d_descrip_ref <- as.data.frame(as.matrix(d_descrip_ref))
d_descrip_ref$id <- seq.int(nrow(d_descrip_ref))

d_descrip_ref



```



```{r}
#check overlaps
#reflex_adpt_keystems
#democratic_keystems
#policy_coh_keystems
#participation_keystems

#intersect(,)

```

```{r}

#d_descrip_demo
#d_descrip_part
#d_descrip_pol
#d_descrip_ref


#descrip_comb <- left_join(d_descrip_demo,d_descrip_part, by = "id") 
#descrip_comb <- left_join(descrip_comb,d_descrip_pol, by = "id") 
#descrip_comb <- left_join(descrip_comb,d_descrip_ref, by = "id")

#descrip_comb


#descrp_list <- sdgacad_df_mini
descrip_comb <- left_join(descrp_list,d_descrip_ref, by = "id") 


descrip_comb


```

```{r}


write.csv(descrip_comb,"C:/Users/caitl/Documents/GitHub/mpp_thesis/exports/descrip_comb.csv", row.names = TRUE)


```










```{r}
#don't push - lots of tried attempts
dfmat_ex <- dfm(tokens(participation$Terms, remove_punct = TRUE))
dfmat_ex


stopWords <- stopwords("en")

participation$dict<- as.character(participation$Terms)
 '%nin%' <- Negate('%in%')
 participation$Terms<-lapply(participation$Terms, function(x) {
  chk <- unlist(strsplit(x," "))
  p <- chk[chk %nin% stopWords]
  paste(p,collapse = " ")
})


dfmat_ex <- dfm(tokens(participation$Terms, remove_punct = TRUE))

participation$dict<- gsub("[[:punct:]]|[[:digit:]]|^http:\\/\\/.*|^https:\\/\\/.*","",participation$dict)
participation$dict<- gsub("\u0092","",participation$dict)

participation$dict





participation_corpus <- Corpus(VectorSource(as.vector(participation$dict))) 
participation_corpus

participation_corpus <- tm_map(participation_corpus, removeWords, stopwords("english"))
trump_corpus <- tm_map(trump_corpus, content_transformer(removePunctuation))


tidy_trump_tweets<- participation %>%
    unnest_tokens("word", text)
 
participation_source <- VectorSource(participation)
df_source <- DataframeSource(participation_source)


```










```{r}
#transform into a leaner dataframe
#authors_list_A_comb <- mutate(authors_list_A, titles=NULL, piece=NULL, weblink=NULL, au_category=NULL)

#adding index as a col for matching
authors_list_A$id <- seq.int(nrow(authors_list_A))

#start to combine
 
authors_list_A_comb <- left_join(authors_list_A,df_au, by = "id") 
authors_list_A_comb <- left_join(authors_list_A_comb,df_cat, by = "id") 


#authors_list_A_comb <- left_join(authors_list_A,df, by = "authors") 
#authors_list_A_comb <- merge(authors_list_A,df, by = "authors")
#authors_list_A_comb <- left_join(authors_list_A_comb,df_agent, by = "authors")
#authors_list_A_comb <- left_join(authors_list_A_comb,df_ngo, by = "category")
#authors_list_A_comb <- left_join(authors_list_A_comb,df_un, by = "authors")
#authors_list_A_comb

authors_list_A_comb$category[authors_list_A_comb$un_programs=="1"] <- "un program"
authors_list_A_comb$category[authors_list_A_comb$un_specialized_agencies=="1"] <- "un specialized agency"
authors_list_A_comb$category[authors_list_A_comb$ngo=="1"] <- "ngo"
authors_list_A_comb$category[authors_list_A_comb$un=="1"] <- "un"


authors_list_A_comb
```

```{r}
#cut unnessesary columns before fixing

#authors_list_A_comb <- mutate(authors_list_A_comb, un_programs=NULL, un_specialized_agencies=NULL, ngo=NULL, un=NULL)

#authors_list_A_comb <- unique(authors_list_A_comb)
#authors_list_A_comb

```





```{r}
#manual fixing based on authors
authors_list_A_comb$category[authors_list_A_comb$authors=="Academy of Korean Studies"] <- "research institute" 



```

```{r}
#------------- category cleanups
authors_list_A_comb$category[authors_list_A_comb$category=="public"] <- "public university"




authors_list_A_comb

```

```{r}
#wider export (useful for checking)
#write.csv(authors_list_A_comb,"C:/Users/caitl/Documents/GitHub/mpp_thesis/exports/authors_list_A_comb.csv", row.names = TRUE)

```


```{r}
#move to wider au_category title
authors_list_A_comb$au_category <-authors_list_A_comb$category

#subet clean
au_category_clean <- authors_list_A_comb[c("titles","authors","au_category")]
au_category_clean



```


```{r}
#export
write.csv(au_category_clean,"C:/Users/caitl/Documents/GitHub/mpp_thesis/exports/au_category_clean.csv", row.names = TRUE)

```














```{r}

au_category_clean <- au_category %>%
 group_by(id) %>%
 summarize(category = str_c(category, collapse = ", "))
au_category_clean 


#separate type text from category
#au_category_clean <- str_split_fixed(au_category_clean$category, "Type,", 2)

au_category_clean <- separate(data = au_category_clean, col = category, into = c("category", "text"), sep = "Type,")

au_category_clean <- separate(data = au_category_clean, col = text, into = c("text", "remainder"), sep = ",")

au_category_clean

#remove redundant cols
au_category_clean <- mutate(au_category_clean, category=NULL, remainder=NULL)

au_category_clean$category <- au_category_clean$text

au_category_clean <- mutate(au_category_clean, text=NULL)

au_category_clean

#reorder
au_category_clean$id <- as.numeric(au_category_clean$id)

au_category_clean[order(au_category_clean$id, decreasing = FALSE),] 

authors_list
authors_list$id <- as.numeric(authors_list$id)




```




```{r}
#probably need later?
authors_corpus <- VCorpus(VectorSource(authors))
# Extra whitespace is eliminated by:
authors_corpus <- tm_map(authors_corpus, stripWhitespace)
# Conversion to lower case by:
authors_corpus <- tm_map(authors_corpus, content_transformer(tolower))
#Removal of stopwords by:
authors_corpus <- tm_map(authors_corpus, removeWords, stopwords("english"))
#Stemming is done by:
tm_map(authors_corpus, stemDocument)

 dtm <- DocumentTermMatrix(authors_corpus)
 inspect(dtm)



```





```{r}
chart_df <- data.frame(titles, authors, tags, SDGs, weblink)

knitr::kable(chart_df  %>% head(10))

chart_df <- tibble::rowid_to_column(chart_df, "id")

```



```{r}

#unsdglearn_subpage <- read_html("https://www.unsdglearn.org/courses/unido-industrial-analytics-platform-iap/")
```

```{r}
#old code
#keywords_nodes <- html_nodes(unsdglearn_subpage, 
#                           xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", #"keyword", " " ))]')
#keywords <- html_text(keywords_nodes)
#keywords


#audience_nodes <- html_nodes(unsdglearn_subpage, 
#                           xpath = '//*[(@id = "content")]//li')
#audience <- html_text(audience_nodes)
#audience


```
```{r}

# Define the KEYWORDS worker function
scraper <- function(weblink) {
  read_html(weblink) %>% 
    html_nodes(xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "keyword", " " ))]') %>% 
    html_text() %>% 
    enframe("id", "keywords")
}

# Iterate over the urls, applying the function each time
keywords <- map_dfr(weblink, scraper, .id = "id")

```


```{r}

# Define the AUDIENCE worker function
scraper <- function(weblink) {
  read_html(weblink) %>% 
    html_nodes(xpath = '//*[contains(concat( " ", @class, " " ), concat( " ", "resource-contentblock", " " )) and (((count(preceding-sibling::*) + 1) = 3) and parent::*)]//*[contains(concat( " ", @class, " " ), concat( " ", "wrapper", " " ))]') %>% 
    html_text() %>% 
    enframe("id", "audience")
}

# Iterate over the urls, applying the function each time
audience <- map_dfr(weblink, scraper, .id = "id")
audience


```


```{r}

#Combine into single columns

keywords_combined <- keywords %>%
 group_by(id) %>%
 summarize(keywords = str_c(keywords, collapse = ", "))

#df3 <- merge(audience, keywords_combined, by = "id")

chart_df <- merge(chart_df, keywords_combined, by = "id")
combined <- merge(chart_df, audience, by = "id", all = TRUE)

write.csv(combined,"C:/Users/caitl/Documents/GitHub/thesis/exports/unsdglearn.csv", row.names = TRUE)


```

```{r}

authors_list <- as.data.frame(authors_list)

write.csv(authors_list,"C:/Users/caitl/Documents/GitHub/mpp_thesis/exports/authors_list.csv", row.names = TRUE)

au_category_clean

au_category_list <- as.data.frame(au_category_clean)

write.csv(au_category_list,"C:/Users/caitl/Documents/GitHub/mpp_thesis/exports/au_category_list.csv", row.names = TRUE)


write.csv(results_urls,"C:/Users/caitl/Documents/GitHub/mpp_thesis/exports/results_urls.csv", row.names = TRUE)

write.csv(au_category_clean,"C:/Users/caitl/Documents/GitHub/mpp_thesis/exports/au_category_clean.csv", row.names = TRUE)


write.csv(authors_list_A,"C:/Users/caitl/Documents/GitHub/mpp_thesis/exports/authors_list_A.csv", row.names = TRUE)

```

```{r}
#long way
#------------------------UN PROGRAMS

un_programs <- c('UN-Habitat|UNDP|UNEP|UN Global Compact')

df <- data.frame(unique(authors_list_A$authors), un_programs = 0)
colnames(df)[1] <- "authors"
df[grep(un_programs, df$authors, value = F), "un_programs"] <- 1
df <- df[order(df$un_programs, decreasing = TRUE),] %>% unique()

df

#------------------------UN SPECIALIZED AGENCIES
un_specialized_agencies <-
  c('FAO|Food and Agriculture Organization of the United Nations|ICAO|International Civil Aviation Organization|IFAD|International Fund for Agricultural Development|ILO|International Labour Organization|IMF|International Monetary Fund|IMO|International Maritime Organization|ITU|International Telecommunication Union|UNESCO|United Nations Educational Scientific and Cultural Organization|UNIDO|United Nations Industrial Development Organization|UNWTO|World Tourism Organization|UPU|Universal Postal Union|WHO|World Health Organization|WIPO|World Intellectual Property Organization|WMO|World Meteorological Organization|World Bank Group|World Bank')
df_agent <- data.frame(authors_list_A$authors, un_specialized_agencies = 0)
colnames(df_agent)[1] <- "authors"
df_agent[grep(pattern = un_specialized_agencies, df_agent$authors, value = F), "un_specialized_agencies"] <- 1
df_agent <- df_agent[order(df_agent$un_specialized_agencies, decreasing = TRUE),] %>% unique()

df_agent

#------------------------UN
un <-
  c('UN DESA|UN Statistics Division|United Nations Statistics Division|United Nations Global Compact Academy|UNDCO|UNGCA|UNITAR')
df_un <- data.frame(authors_list_A$authors, un = 0)
colnames(df_un)[1] <- "authors"
df_un[grep(un, df_un$authors, value = F), "un"] <- 1
df_un <- df_un[order(df_un$un, decreasing = TRUE),] %>% unique()
df_un

#sapply(un, function(x) df_un$authors[grepl(x, df_un$authors)])

#sapply(un, function(x) df_un[grepl(x, un)])



#------------------------NONProfit
#space clear rm(unsdglearn,unsdglearn_silos,coursera)
ngo <-
  c('501','nonprofit','non-profit','non-governmental','nongovernmental','Non-governmental organization','Non-governmental','NGO','ngo','ingo','nongovernmental','philanthropic initiative')
df_ngo <- data.frame(authors_list_A$category, ngo = 0)
colnames(df_ngo)[1] <- "category"
df_ngo[grep(pattern = ngo, df_ngo$category, value = F), "ngo"] <- 1
df_ngo <- df_ngo[order(df_ngo$ngo, decreasing = TRUE),] %>% unique()
df_ngo

#sapply(ngo, function(x) df_ngo$authors[grepl(x, df_ngo$authors)])


#------------------



#------------------ If Coded, Change Category
#df
#df_agent 262
#authors_list_A
#add on new columns
#522
#authors_list_A
#df

```

```
